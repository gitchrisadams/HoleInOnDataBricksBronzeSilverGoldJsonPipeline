# Databricks notebook source
# MAGIC %md
# MAGIC ### Example Exploratory Notebook
# MAGIC
# MAGIC Use this notebook to explore the data generated by the pipeline in your preferred programming language.
# MAGIC
# MAGIC **Note**: This notebook is not executed as part of the pipeline.

# COMMAND ----------

# df = spark.read.option("multiline", "true").json("/Volumes/hole_in_one/hole_in_one_schema/hole_in_one_volume/data.json")
# # display(df)
# single_file_output_path = "/Volumes/hole_in_one/hole_in_one_schema/hole_in_one_volume/data_silver"
# new_output_path = "/Volumes/hole_in_one/hole_in_one_schema/hole_in_one_volume/data_silver.json"
# df.coalesce(1).write.format("json").mode("overwrite").save(single_file_output_path)

# list_files = dbutils.fs.ls(single_file_output_path)
# print("list files: ", list_files)
# json_file_path = [file.path for file in list_files if '.json' in file.path][0]
# print("json_file_paht", json_file_path)
# dbutils.fs.mv(json_file_path, new_output_path)
# dbutils.fs.rm(single_file_output_path, True)







# COMMAND ----------


